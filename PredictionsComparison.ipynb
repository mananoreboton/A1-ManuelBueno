{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f663d3-74aa-48bf-b79c-24f3e4a6ff5e",
   "metadata": {},
   "source": [
    "## Select and analysis dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a47ea4-2c63-4128-b5fd-8e3b184dd56e",
   "metadata": {},
   "source": [
    "First, we call PreprocessData.select_and_analyze_dataset() to prepare the input dataset and save the train and test data to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0eaa87-096f-4a30-b641-a9b98111760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreprocessData initialized.\n",
      "Reading data from ./data/kc_house_data.csv...\n",
      "Truncating data randomly to 2000 rows\n",
      "Selecting this columns from the data: ['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'yr_built', 'lat', 'long', 'price']\n",
      "Removing missing values from columns: ['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'yr_built', 'lat', 'long', 'price']\n",
      "Removing outliers values from columns: []\n",
      "Splitting data: train_data (1600) and test_data (400)\n",
      "Creating ColumnTransformer\n",
      "Fit train_data\n",
      "Transforming train_data and test_data\n",
      "Train matrix saved to ./data/transformed_train_matrix.csv\n",
      "Test matrix saved to ./data/transformed_test_matrix.csv\n",
      "Transformer saved to ./data/transformer.pkl\n",
      "Executed all subtasks of select and analyze dataset...\n"
     ]
    }
   ],
   "source": [
    "from PreprocessData import PreprocessData\n",
    "preprocessData = PreprocessData()\n",
    "preprocessData.select_and_analyze_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66ef60-367a-4c39-92d7-8ec1f31a5b52",
   "metadata": {},
   "source": [
    "## Hyperparameter comparison and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf4cad-48d8-49be-bf9b-ffc0b941adcf",
   "metadata": {},
   "source": [
    "We will explore some of the space of hyperparameters, trying different combinations and \n",
    "evaluating the quality of the result of the prediction obtained using them.\n",
    "\n",
    "For that, we load the hyperparameter combinations and the transformed train dataset from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64a94480-6bd7-457f-a9ed-02dc1bfc6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Number of Layers        Layer Structure  Num Epochs  Learning Rate  \\\n",
      "0                  3            [13, 64, 1]         100         0.0010   \n",
      "1                  4       [13, 128, 64, 1]         150         0.0005   \n",
      "2                  2                [13, 1]          80         0.0020   \n",
      "3                  3       [13, 128, 64, 1]         120         0.0010   \n",
      "4                  5  [13, 256, 128, 64, 1]         200         0.0001   \n",
      "5                  4       [13, 128, 64, 1]         150         0.0005   \n",
      "6                  3            [13, 64, 1]         100         0.0010   \n",
      "7                  5  [13, 256, 128, 64, 1]         200         0.0002   \n",
      "8                  4           [13, 128, 1]         140         0.0005   \n",
      "9                  5  [13, 256, 128, 64, 1]         250         0.0001   \n",
      "10                 3            [13, 64, 1]         180         0.0005   \n",
      "\n",
      "    Momentum Activation Function  \n",
      "0       0.90                relu  \n",
      "1       0.95                tanh  \n",
      "2       0.85             sigmoid  \n",
      "3       0.90                relu  \n",
      "4       0.95              linear  \n",
      "5       0.90                 elu  \n",
      "6       0.85                tanh  \n",
      "7       0.95             sigmoid  \n",
      "8       0.90                relu  \n",
      "9       0.95             sigmoid  \n",
      "10      0.85                 elu  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hyperparameters = pd.read_csv(\"data/neural_network_parameters.csv\")\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96718adb-05c5-4f52-90d4-ffdd2e58dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30319149 0.375      0.21875    0.10521739 0.00652308 1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.5\n",
      "  0.4        0.57391304 0.65979557 0.2078922 ]]\n",
      "[0.04393443]\n"
     ]
    }
   ],
   "source": [
    "X_in, y_in = preprocessData.read_transformed_data_from_file()\n",
    "print(X_in[:1])\n",
    "print(y_in[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9edca-c4c4-4d96-a128-97f983757f72",
   "metadata": {},
   "source": [
    "For each iteration over the combinations: \n",
    "- we create a new instance of the NeuralNet with the hyperparameters,\n",
    "- call the NeuralNet.fit() function with Y_in (instances) and y_in (ground truth target values) to train our neuronal network,\n",
    "- call the NeuralNet.predict() function to obtain the estimated target values (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "470f1a91-e12a-4a2f-bdc4-125eff03a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet initialized.\n",
      "NeuralNet initialized.\n",
      "NeuralNet initialized.\n",
      "NeuralNet initialized.\n",
      "NeuralNet initialized.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported activation function name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNeuralNet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralNet\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, params \u001b[38;5;129;01min\u001b[39;00m hyperparameters\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 3\u001b[0m     neural_net \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNumber of Layers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLayer Structure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert string to list\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNum Epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLearning Rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActivation Function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/nec/nec_a1/NeuralNet.py:32\u001b[0m, in \u001b[0;36mNeuralNet.__init__\u001b[0;34m(self, L, n, n_epochs, learning_rate, momentum, activation_function, validation_split)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_w \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_theta \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_function, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_derivative \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_activation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_errors \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/code/nec/nec_a1/NeuralNet.py:159\u001b[0m, in \u001b[0;36mNeuralNet.get_activation_function\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mones_like(x)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported activation function name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m activation, derivative\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported activation function name"
     ]
    }
   ],
   "source": [
    "from NeuralNet import NeuralNet\n",
    "for _, params in hyperparameters.iterrows():\n",
    "    neural_net = NeuralNet(\n",
    "        L = params[\"Number of Layers\"],\n",
    "        n = eval(params[\"Layer Structure\"]),  # Convert string to list\n",
    "        n_epochs = params[\"Num Epochs\"],\n",
    "        learning_rate = params[\"Learning Rate\"],\n",
    "        momentum = params[\"Momentum\"],\n",
    "        activation_function = params[\"Activation Function\"],\n",
    "        validation_split = 0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576804b0-f4e1-4e7f-b69c-bcfb35dc3367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
