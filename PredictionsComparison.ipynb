{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f663d3-74aa-48bf-b79c-24f3e4a6ff5e",
   "metadata": {},
   "source": [
    "## Select and analysis dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a47ea4-2c63-4128-b5fd-8e3b184dd56e",
   "metadata": {},
   "source": [
    "First, we call PreprocessData.select_and_analyze_dataset() to prepare the input dataset and save the train and test data to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0eaa87-096f-4a30-b641-a9b98111760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreprocessData initialized.\n",
      "Reading data from ./data/kc_house_data.csv...\n",
      "Truncating data randomly to 2000 rows\n",
      "Selecting this columns from the data: ['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'yr_built', 'lat', 'long', 'price']\n",
      "Removing missing values from columns: ['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'yr_built', 'lat', 'long', 'price']\n",
      "Removing outliers values from columns: []\n",
      "Splitting data: train_data (1600) and test_data (400)\n",
      "Creating ColumnTransformer\n",
      "Fit train_data\n",
      "Transforming train_data and test_data with columns: '['date__days_since_first_date' 'bedrooms__bedrooms' 'bathrooms__bathrooms'\n",
      " 'sqft_living__sqft_living' 'sqft_lot__sqft_lot' 'floors__floors_1.0'\n",
      " 'floors__floors_1.5' 'floors__floors_2.0' 'floors__floors_2.5'\n",
      " 'floors__floors_3.0' 'floors__floors_3.5' 'waterfront__waterfront_1'\n",
      " 'view__view_0' 'view__view_1' 'view__view_2' 'view__view_3'\n",
      " 'view__view_4' 'condition__condition' 'grade__grade' 'yr_built__yr_built'\n",
      " 'lat__lat' 'long__long' 'price__price' 'geo__cluster_0_coordinates'\n",
      " 'geo__cluster_1_coordinates' 'geo__cluster_2_coordinates'\n",
      " 'geo__cluster_3_coordinates' 'geo__cluster_4_coordinates'\n",
      " 'geo__cluster_5_coordinates' 'geo__cluster_6_coordinates'\n",
      " 'geo__cluster_7_coordinates' 'geo__cluster_8_coordinates'\n",
      " 'geo__cluster_9_coordinates']'\n",
      "Train matrix saved to ./data/transformed_train_matrix.csv\n",
      "Test matrix saved to ./data/transformed_test_matrix.csv\n",
      "Transformer saved to ./data/transformer.pkl\n",
      "Executed all subtasks of select and analyze dataset...\n"
     ]
    }
   ],
   "source": [
    "from PreprocessData import PreprocessData\n",
    "preprocessData = PreprocessData()\n",
    "preprocessData.select_and_analyze_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66ef60-367a-4c39-92d7-8ec1f31a5b52",
   "metadata": {},
   "source": [
    "## Hyperparameter comparison and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf4cad-48d8-49be-bf9b-ffc0b941adcf",
   "metadata": {},
   "source": [
    "We will explore some of the space of hyperparameters, trying different combinations and \n",
    "evaluating the quality of the result of the prediction obtained using them.\n",
    "\n",
    "For that, we load the hyperparameter combinations and the transformed train dataset from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a94480-6bd7-457f-a9ed-02dc1bfc6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Number of Layers     Layer Structure  Num Epochs  Learning Rate  Momentum  \\\n",
      "0                  3          [32, 5, 1]         100          0.001      0.85   \n",
      "1                  4      [32, 12, 5, 1]         150          0.005      0.95   \n",
      "2                  5  [32, 44, 12, 5, 1]         350          0.010      0.95   \n",
      "3                  5  [32, 44, 12, 5, 1]         350          0.010      0.95   \n",
      "4                  5  [32, 44, 12, 5, 1]         250          0.010      0.90   \n",
      "5                  5  [32, 44, 12, 5, 1]         250          0.001      0.95   \n",
      "6                  5  [32, 44, 12, 5, 1]         350          0.010      0.95   \n",
      "7                  4      [32, 32, 5, 1]         350          0.010      0.95   \n",
      "8                  4      [32, 44, 7, 1]         250          0.010      0.95   \n",
      "9                  5  [32, 44, 12, 5, 1]         250          0.010      0.95   \n",
      "10                 3          [32, 5, 1]         180          0.005      0.85   \n",
      "\n",
      "   Activation Function  \n",
      "0                 relu  \n",
      "1                 tanh  \n",
      "2                 tanh  \n",
      "3                 relu  \n",
      "4              sigmoid  \n",
      "5              sigmoid  \n",
      "6              sigmoid  \n",
      "7              sigmoid  \n",
      "8              sigmoid  \n",
      "9              sigmoid  \n",
      "10                relu  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hyperparameters = pd.read_csv(\"data/neural_network_parameters.csv\")\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96718adb-05c5-4f52-90d4-ffdd2e58dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading X and y data from file './data/transformed_train_matrix.csv' with target 'price__price'\n",
      "[[0.30319149 0.63092975 0.21875    0.10521739 0.00652308 1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.5\n",
      "  0.4        0.57391304 0.65979557 0.2078922  0.99710744 0.90097191\n",
      "  0.93686882 0.98647746 0.94869553 0.9678369  0.86959061 0.94195378\n",
      "  0.78141002 0.98446017]]\n",
      "[0.04393443]\n"
     ]
    }
   ],
   "source": [
    "X_in, y_in = preprocessData.read_transformed_data_from_file()\n",
    "print(X_in[:1])\n",
    "print(y_in[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9edca-c4c4-4d96-a128-97f983757f72",
   "metadata": {},
   "source": [
    "For each iteration over the combinations: \n",
    "- we create a new instance of the NeuralNet with the hyperparameters,\n",
    "- call the NeuralNet.fit() function with Y_in (instances) and y_in (ground truth target values) to train our neuronal network,\n",
    "- call the NeuralNet.predict() function to obtain the estimated target values (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470f1a91-e12a-4a2f-bdc4-125eff03a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combination 0 ---\n",
      "NeuralNet initialized with self.L = '3', self.n = '[32, 5, 1]', self.n_epochs = '100', self.learning_rate = '0.001', self.momentum = '0.85', self.fact = 'relu', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 1 ---\n",
      "NeuralNet initialized with self.L = '4', self.n = '[32, 12, 5, 1]', self.n_epochs = '150', self.learning_rate = '0.005', self.momentum = '0.95', self.fact = 'tanh', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 2 ---\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'tanh', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 3 ---\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'relu', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 4 ---\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '250', self.learning_rate = '0.01', self.momentum = '0.9', self.fact = 'sigmoid', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 5 ---\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '250', self.learning_rate = '0.001', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 6 ---\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 7 ---\n",
      "NeuralNet initialized with self.L = '4', self.n = '[32, 32, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 8 ---\n",
      "NeuralNet initialized with self.L = '4', self.n = '[32, 44, 7, 1]', self.n_epochs = '250', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 9 ---\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '250', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n",
      "--- Combination 10 ---\n",
      "NeuralNet initialized with self.L = '3', self.n = '[32, 5, 1]', self.n_epochs = '180', self.learning_rate = '0.005', self.momentum = '0.85', self.fact = 'relu', self.validation_split = '0.2'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing loss_epochs()\n"
     ]
    }
   ],
   "source": [
    "from NeuralNet import NeuralNet\n",
    "\n",
    "neural_net_result_params = {}\n",
    "for i, params in hyperparameters.iterrows():\n",
    "    print(f\"--- Combination {i} ---\")\n",
    "    neural_net = NeuralNet(\n",
    "        L = params[\"Number of Layers\"],\n",
    "        n = eval(params[\"Layer Structure\"]),  # Convert string to list\n",
    "        n_epochs = params[\"Num Epochs\"],\n",
    "        learning_rate = params[\"Learning Rate\"],\n",
    "        momentum = params[\"Momentum\"],\n",
    "        activation_function = params[\"Activation Function\"],\n",
    "        validation_split = 0.2\n",
    "    )\n",
    "\n",
    "    neural_net.fit(X_in, y_in)\n",
    "    y_pred = neural_net.predict(X_in)\n",
    "    epoch_loss = neural_net.loss_epochs()\n",
    "\n",
    "    neural_net_result_params[i] = {\n",
    "        \"Combination\": i,\n",
    "        \"Hyperparameters\": params.to_dict(),\n",
    "        \"Y_pred\": y_pred,\n",
    "        \"Epoch_loss\": epoch_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a3565-e8de-450b-aa61-9c43f248119e",
   "metadata": {},
   "source": [
    "neural_net_result_params is a dictionary that contains the info about each combinations of hyperparameter and the result of their predictions. For example we will show the contain of the first element (0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39a415-dd38-4a59-996b-2ea0ed91adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neural_net_result_params[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe3dcf-86eb-4510-9699-3dae78498f8a",
   "metadata": {},
   "source": [
    "Now we can calculate MSE(Mean Squared Error), MAE (Mean Absolute Error) and MAPE (Mean Absolute Percentage Error), and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4522ad0-8094-4ff9-a1bf-f8ce1c4d375a",
   "metadata": {},
   "source": [
    "After execution the predictions, if  NaN values are generated, we delete the result for that combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162b1a0-1b2d-4aa5-921c-a04898e48d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "i = 0\n",
    "while i < len(neural_net_result_params):\n",
    "    if np.isnan(neural_net_result_params[i][\"Y_pred\"]).any():\n",
    "        print(f\"Handling NaN in Combination {neural_net_result_params[i]['Combination']}\")\n",
    "        del neural_net_result_params[i]\n",
    "    i += 1\n",
    "neural_net_result_params = neural_net_result_params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576804b0-f4e1-4e7f-b69c-bcfb35dc3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "for key, result in neural_net_result_params.items():\n",
    "    y_pred = result[\"Y_pred\"]\n",
    "    \n",
    "    mse = mean_squared_error(y_in, y_pred)\n",
    "    mae = mean_absolute_error(y_in, y_pred)\n",
    "    mape = sum(abs((y_true - y_pred_val) / y_true) for y_true, y_pred_val in zip(y_in, y_pred) if y_true != 0) / len(y_in)\n",
    "\n",
    "    result[\"MSE\"] = mse\n",
    "    result[\"MAE\"] = mae\n",
    "    result[\"MAPE\"] = mape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b89d5-7321-46fc-9038-623c6938798e",
   "metadata": {},
   "source": [
    "For each combination of hiperparameters we now have values of MSE, MAE and MAPE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1d5e1-b8bf-42aa-b57d-42548b52d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neural_net_result_params[0][\"MSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea1a67-bd7e-47e3-ac93-3b6b0090b8f8",
   "metadata": {},
   "source": [
    "We can compare the performance of the combinations of hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51dae8f-29b7-47f3-8759-51064846c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for key, result in neural_net_result_params.items():\n",
    "    hyperparams = result[\"Hyperparameters\"]\n",
    "    data.append({\n",
    "        \"Combination\": key,\n",
    "        \"Number of Layers\": hyperparams[\"Number of Layers\"],\n",
    "        \"Layer Structure\": hyperparams[\"Layer Structure\"],\n",
    "        \"Num Epochs\": hyperparams[\"Num Epochs\"],\n",
    "        \"Learning Rate\": hyperparams[\"Learning Rate\"],\n",
    "        \"Momentum\": hyperparams[\"Momentum\"],\n",
    "        \"Activation Function\": hyperparams[\"Activation Function\"],\n",
    "        \"MAPE\": result[\"MAPE\"],\n",
    "        \"MAE\": result[\"MAE\"],\n",
    "        \"MSE\": result[\"MSE\"]\n",
    "    })\n",
    "\n",
    "hyperparameters_performance_results = pd.DataFrame(data)\n",
    "hyperparameters_performance_results = hyperparameters_performance_results.sort_values(\n",
    "    by=[\"MAPE\"],\n",
    "    ascending=[True]\n",
    ")\n",
    "hyperparameters_performance_results.to_csv(\"./data/hyperparameters_performance_results.csv\", index=False)\n",
    "print(\"Data frame saved to 'hyperparameters_performance_results.csv' with the following columns:\")\n",
    "print(hyperparameters_performance_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e887606-cec5-4316-ba93-d92033ae3535",
   "metadata": {},
   "source": [
    "These are the scatter plots of the Prediction Value vs Real Value of the combinations with lowest MAPE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218028c-1fa6-4d04-bf8a-b877d18d4c75",
   "metadata": {},
   "source": [
    "Sort results by MAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644b96-764a-49a0-ac78-23872147b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net_result_params_first_items = sorted(neural_net_result_params.items(), key=lambda x: x[1][\"MAE\"])[:3]\n",
    "y_pred_bp = neural_net_result_params_first_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748f41f-e118-4382-a1b5-45912f3edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# n = len(neural_net_result_params)\n",
    "n = 3\n",
    "fig, axes = plt.subplots(n, 1, figsize=(5, 3*n))\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (key, value) in enumerate(neural_net_result_params_first_items):\n",
    "    Yi_pred = value[\"Y_pred\"]\n",
    "    Yi_pred = Yi_pred.reshape(-1)\n",
    "\n",
    "    axes[i].scatter(y_in, Yi_pred)\n",
    "    axes[i].set_title(f'Execution {value[\"Combination\"]}')\n",
    "    axes[i].set_xlabel('Real Y')\n",
    "    axes[i].set_ylabel('Predicted Y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03109a2-d6a4-4a5e-b953-589c4ab3364d",
   "metadata": {},
   "source": [
    "And These are the scatter plots of the evolution of the training and validation error as a function\n",
    "of the number of epochs of the combinations with lowest MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe38e53-4c4a-492a-8df7-278afe71dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# n = len(neural_net_result_params)\n",
    "n = 3\n",
    "fig, axes = plt.subplots(n, 1, figsize=(7, 3*n))\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (key, value) in enumerate(neural_net_result_params_first_items):\n",
    "    training_errors, validation_errors = value[\"Epoch_loss\"]\n",
    "    epochs = range(1, len(training_errors) + 1)\n",
    "    \n",
    "    axes[i].plot(epochs, training_errors, label='Training Error', marker='o')\n",
    "    axes[i].plot(epochs, validation_errors, label='Validation Error', marker='s')\n",
    "    axes[i].set_title(f'Execution {value[\"Combination\"]}')\n",
    "    axes[i].set_xlabel('Epoch')\n",
    "    axes[i].set_ylabel('Error')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938d7e7-6930-48e4-a20a-00432b68851f",
   "metadata": {},
   "source": [
    "## Model result comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543cd91-aea8-466c-ac96-685e4091deb8",
   "metadata": {},
   "source": [
    "First, we are going to use the sklearn library to obtain new predictions from a linear regression model. We train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b226b-c55d-4731-af44-797ce296bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_comp, X_test_comp, y_train_comp, y_test_comp = train_test_split(X_in, y_in, test_size=0.2, random_state=31)\n",
    "linear_regression_model = LinearRegression(fit_intercept=True, n_jobs=None)\n",
    "linear_regression_model.fit(X_train_comp, y_train_comp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88ed84-1eab-4eb4-833c-1b93f1af2633",
   "metadata": {},
   "source": [
    "And start the prediction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c35f9-88e6-4746-bea0-367657006d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlr = linear_regression_model.predict(X_in)\n",
    "y_pred_mlr[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7fbef-679f-4357-9caa-e8ba677b0c0a",
   "metadata": {},
   "source": [
    "The next step is to obtain new predictions from a multi layer neural network using the Keras library. For that we:\n",
    "1. Define new hyperparameters.\n",
    "2. Build multi-layer model\n",
    "3. Train model\n",
    "4. Predict a new y values\n",
    "\n",
    "Note: There may be an expected warning message related to urllib3 v2 when the tensorflow library is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5017086-b099-4153-9c15-34b0e66ee91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "keras_input_dim = X_train_comp.shape[1]\n",
    "keras_hidden_units_1 = 12\n",
    "keras_hidden_units_2 = 7\n",
    "keras_activation = 'relu'\n",
    "keras_output_activation = 'linear'\n",
    "keras_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "keras_loss = 'mse'\n",
    "keras_epochs = 100\n",
    "keras_batch_size = 32 # should we size of X_train_comp.shape[0]?\n",
    "print(f\"Checking number of features for input layer: {keras_input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ca1b8-caa5-47f5-a4b0-753184db54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "keras_model = models.Sequential([\n",
    "    layers.Input(shape=(keras_input_dim,)),\n",
    "    layers.Dense(keras_hidden_units_1, activation=keras_activation),\n",
    "    layers.Dense(keras_hidden_units_2, activation=keras_activation),\n",
    "    layers.Dense(1, activation=keras_output_activation)\n",
    "])\n",
    "\n",
    "keras_model.compile(optimizer = keras_optimizer, loss = keras_loss, metrics = ['mae'])\n",
    "print(f\"Checking multi-layer model is built: {keras_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9ead3-f281-46e5-9d0f-7ee1e4c0a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "keras_scaler = StandardScaler()\n",
    "X_train_comp_scaled = keras_scaler.fit_transform(X_train_comp) #Should we trasnform X again?\n",
    "keras_history = keras_model.fit(X_train_comp_scaled, y_train_comp,\n",
    "                          epochs = keras_epochs,\n",
    "                          batch_size = keras_batch_size,\n",
    "                          validation_split = 0.2,\n",
    "                          verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cee3c-61e2-44e8-b173-a2c61330a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in_scaled = keras_scaler.fit_transform(X_in)\n",
    "y_pred_keras = keras_model.predict(X_in_scaled).flatten()\n",
    "y_pred_keras[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bb379-ac19-486b-8aa1-13def223efa3",
   "metadata": {},
   "source": [
    "Now we calculate MAE, MSE and MAPE for both y_pred_mlr and y_pred_keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b43a7-e8fd-4b13-9652-aaf26d393766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred):\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mse = np.mean((y_true - y_pred)**2)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    return mae, mse, mape\n",
    "\n",
    "y_pred_bp_as_array = y_pred_bp[1]['Y_pred'] # Extract data from structure\n",
    "\n",
    "mae_pred_bp, mse_pred_bp, mape_pred_bp = metrics(y_in, y_pred_bp_as_array)\n",
    "mae_pred_mlr, mse_pred_mlr, mape_pred_mlr = metrics(y_in, y_pred_mlr)\n",
    "mae_pred_keras, mse_pred_keras, mape_pred_keras = metrics(y_in, y_pred_keras)\n",
    "\n",
    "model_comparison_results = pd.DataFrame({\n",
    "    'Error measures': ['MAE', 'MSE', 'MAPE'],\n",
    "    'BP': [mae_pred_bp, mse_pred_bp, mape_pred_bp],\n",
    "    'MLR-F': [mae_pred_mlr, mse_pred_mlr, mape_pred_mlr],\n",
    "    'BP-F': [mae_pred_keras, mse_pred_keras, mape_pred_keras]\n",
    "})\n",
    "\n",
    "print(model_comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a7636-bcec-457d-82e4-503f53a5247a",
   "metadata": {},
   "source": [
    "Now we show scatter plots of predicted vs real values for BP (manually), MLR-F, BP-F models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cfc6a-366c-45dc-8111-d2ab25625a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_in, y_pred_mlr, alpha=0.5, label='MLR-F')\n",
    "plt.scatter(y_in, y_pred_keras, alpha=0.5, label='BP-F')\n",
    "plt.scatter(y_in, y_pred_bp_as_array, alpha=0.5, label='BP (manually)')\n",
    "\n",
    "# Plot a line for reference\n",
    "min_val = min(y_in.min(), y_pred_bp_as_array.min(), y_pred_mlr.min(), y_pred_keras.min())\n",
    "max_val = max(y_in.max(), y_pred_bp_as_array.max(), y_pred_mlr.max(), y_pred_keras.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='1:1 line')\n",
    "\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs True Values for the three Models')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a6e17-4d47-4a62-b4d7-7c48344146b3",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01e00b-dd4a-4717-976b-52956c8c8770",
   "metadata": {},
   "source": [
    "We used our manually created `NeuralNet`, `NeuralNetPredictor` and `PredictorExecutor` classes to execute **k-fold cross-validation** over an 1000 instances dataset to assess the performance of our different hyperparameter combinations defined in the _'neural_network_parameters.csv'_ files (also available at the cross-validation-results folder).\n",
    "\n",
    "For **Negative MAE** these are the results:\n",
    "\n",
    "| N. of Layers | Layer Structure    | Num Epochs | Learning Rate | Momentum | Activation Func. | Mean       | Variance    |\n",
    "|--------------|--------------------|------------|---------------|----------|------------------|------------|-------------|\n",
    "| 3            | [32, 5, 1]         | 100        | 0.001         | 0.85     | relu             | -0.0610646 | 2.25502e-05 |\n",
    "| 4            | [32, 12, 5, 1]     | 150        | 0.005         | 0.95     | tanh             | -0.0271284 | 7.43315e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | tanh             | -0.0206829 | 1.22648e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | relu             | -0.0610646 | 2.25502e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.01          | 0.9      | sigmoid          | -0.0264958 | 1.74208e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.001         | 0.95     | sigmoid          | -0.0283447 | 1.62428e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | sigmoid          | -0.0179797 | 6.10538e-06 |\n",
    "| 4            | [32, 32, 5, 1]     | 350        | 0.01          | 0.95     | sigmoid          | -0.017877  | 7.71762e-06 |\n",
    "| 4            | [32, 44, 7, 1]     | 250        | 0.01          | 0.95     | sigmoid          | -0.0171507 | 1.26287e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.01          | 0.95     | sigmoid          | -0.0181939 | 9.37823e-06 |\n",
    "| 3            | [32, 5, 1]         | 180        | 0.005         | 0.85     | relu             | -0.0626909 | 4.56893e-05 |\n",
    "\n",
    "For **Negative MSE** these are the results:\n",
    "\n",
    "| N. of Layers | Layer Structure    | Num Epochs | Learning Rate | Momentum | Activation Func. | Mean        | Variance    |\n",
    "|--------------|--------------------|------------|---------------|----------|------------------|-------------|-------------|\n",
    "| 3            | [32, 5, 1]         | 100        | 0.001         | 0.85     | relu             | -0.00268342 | 7.13703e-06 |\n",
    "| 4            | [32, 12, 5, 1]     | 150        | 0.005         | 0.95     | tanh             | -0.00315976 | 6.13253e-06 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | tanh             | -0.0026338  | 1.29018e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | relu             | -0.00652708 | 1.11375e-05 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.01          | 0.9      | sigmoid          | -0.00182747 | 5.5904e-06  |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.001         | 0.95     | sigmoid          | -0.00260613 | 8.42557e-06 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | sigmoid          | -0.00136719 | 2.26853e-06 |\n",
    "| 4            | [32, 32, 5, 1]     | 350        | 0.01          | 0.95     | sigmoid          | -0.0012032  | 1.63084e-06 |\n",
    "| 4            | [32, 44, 7, 1]     | 250        | 0.01          | 0.95     | sigmoid          | -0.00117807 | 1.89067e-06 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.01          | 0.95     | sigmoid          | -0.00143667 | 4.13801e-06 |\n",
    "| 3            | [32, 5, 1]         | 180        | 0.005         | 0.85     | relu             | -0.00652708 | 1.11375e-05 |\n",
    "\n",
    "For **Negative MAPE** these are the results:\n",
    "\n",
    "| N. of Layers | Layer Structure    | Num Epochs | Learning Rate | Momentum | Activation Func. | Mean      | Variance   |\n",
    "|--------------|--------------------|------------|---------------|----------|------------------|-----------|------------|\n",
    "| 3            | [32, 5, 1]         | 100        | 0.001         | 0.85     | relu             | -1        | 0          |\n",
    "| 4            | [32, 12, 5, 1]     | 150        | 0.005         | 0.95     | tanh             | -0.489261 | 0.00995061 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | tanh             | -0.560644 | 0.0687754  |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | relu             | -1        | 0          |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.01          | 0.9      | sigmoid          | -0.534834 | 0.00143487 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.001         | 0.95     | sigmoid          | -0.73224  | 0.00366142 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 350        | 0.01          | 0.95     | sigmoid          | -0.299791 | 0.00123542 |\n",
    "| 4            | [32, 32, 5, 1]     | 350        | 0.01          | 0.95     | sigmoid          | -0.327576 | 0.00178844 |\n",
    "| 4            | [32, 44, 7, 1]     | 250        | 0.01          | 0.95     | sigmoid          | -0.392357 | 0.00599126 |\n",
    "| 5            | [32, 44, 12, 5, 1] | 250        | 0.01          | 0.95     | sigmoid          | -0.358972 | 0.00160058 |\n",
    "| 3            | [32, 5, 1]         | 180        | 0.005         | 0.85     | relu             | -1        | 0          |\n",
    "\n",
    "\n",
    "Below there is a quick demo, with a smaller subset of the data, on how to call `PredictorExecutor` to execute de cross validation. `neg_mean_absolute_error`, `neg_mean_squared_error` or `neg_mean_absolute_percentage_error` can be used according to the wanted scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3148699f-01c3-4323-abbd-8acf01e5679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreprocessData initialized.\n",
      "Reading X and y data from file './data/transformed_train_matrix.csv' with target 'price__price'\n",
      "NeuralNet initialized with self.L = '3', self.n = '[32, 5, 1]', self.n_epochs = '100', self.learning_rate = '0.001', self.momentum = '0.85', self.fact = 'relu', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '0' in './data/cross_validation_with_hyperparameters_0_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '4', self.n = '[32, 12, 5, 1]', self.n_epochs = '150', self.learning_rate = '0.005', self.momentum = '0.95', self.fact = 'tanh', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '1' in './data/cross_validation_with_hyperparameters_1_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'tanh', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '2' in './data/cross_validation_with_hyperparameters_2_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'relu', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '3' in './data/cross_validation_with_hyperparameters_3_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '250', self.learning_rate = '0.01', self.momentum = '0.9', self.fact = 'sigmoid', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '4' in './data/cross_validation_with_hyperparameters_4_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '250', self.learning_rate = '0.001', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '5' in './data/cross_validation_with_hyperparameters_5_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '6' in './data/cross_validation_with_hyperparameters_6_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '4', self.n = '[32, 32, 5, 1]', self.n_epochs = '350', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '7' in './data/cross_validation_with_hyperparameters_7_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '4', self.n = '[32, 44, 7, 1]', self.n_epochs = '250', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '8' in './data/cross_validation_with_hyperparameters_8_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '5', self.n = '[32, 44, 12, 5, 1]', self.n_epochs = '250', self.learning_rate = '0.01', self.momentum = '0.95', self.fact = 'sigmoid', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '9' in './data/cross_validation_with_hyperparameters_9_neg_mean_absolute_error.csv'\n",
      "NeuralNet initialized with self.L = '3', self.n = '[32, 5, 1]', self.n_epochs = '180', self.learning_rate = '0.005', self.momentum = '0.85', self.fact = 'relu', self.validation_split = '0'\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Executing fit(X, y)\n",
      "Executing predict(X)\n",
      "Saving Cross Validation ccore list for case '10' in './data/cross_validation_with_hyperparameters_10_neg_mean_absolute_error.csv'\n",
      "  Number of Layers  Layer Structure       Num Epochs    Learning Rate    Momentum  Activation Function    Scores                                                                          Mean     Variance\n",
      "------------------  ------------------  ------------  ---------------  ----------  ---------------------  ------------------------------------------------------------------------  ----------  -----------\n",
      "                 3  [32, 5, 1]                   100            0.001        0.85  relu                   [-0.04393443 -0.6962617  -0.1012459  -0.04918033 -0.08786885 -0.01180328  -0.122479   0.0372672\n",
      "                                                                                                           -0.08170492 -0.03213115 -0.07540984 -0.0452459 ]\n",
      "                 4  [32, 12, 5, 1]               150            0.005        0.95  tanh                   [-0.02835703 -0.01225631 -0.41811435 -0.00278032 -0.02540272 -0.0938663   -0.0670096  0.0142858\n",
      "                                                                                                           -0.03180491 -0.00618964 -0.03449434 -0.01682997]\n",
      "                 5  [32, 44, 12, 5, 1]           350            0.01         0.95  tanh                   [-0.01553176 -0.05900531 -0.05871281 -0.00018968 -0.029372   -0.02709429  -0.0326037  0.000350263\n",
      "                                                                                                           -0.04863318 -0.03230235 -0.01286995 -0.04232608]\n",
      "                 5  [32, 44, 12, 5, 1]           350            0.01         0.95  relu                   [-0.04393443 -0.04983607 -0.1012459  -0.04918033 -0.08786885 -0.01180328  -0.0578361  0.000693539\n",
      "                                                                                                           -0.08170492 -0.03213115 -0.07540984 -0.0452459 ]\n",
      "                 5  [32, 44, 12, 5, 1]           250            0.01         0.9   sigmoid                [-0.02120567 -0.00931593 -0.03908448 -0.01449905 -0.02804817 -0.05562421  -0.0259334  0.000175708\n",
      "                                                                                                           -0.02022029 -0.03408156 -0.01301119 -0.02424345]\n",
      "                 5  [32, 44, 12, 5, 1]           250            0.001        0.95  sigmoid                [-0.03839998 -0.03418852 -0.02280385 -0.03007627 -0.00558254 -0.07100708  -0.0295255  0.000429653\n",
      "                                                                                                           -0.00099439 -0.05137387 -0.00628704 -0.03454128]\n",
      "                 5  [32, 44, 12, 5, 1]           350            0.01         0.95  sigmoid                [-0.01682413 -0.00442556 -0.05053645 -0.00846333 -0.03257449 -0.05294664  -0.0241407  0.000304138\n",
      "                                                                                                           -0.02555759 -0.03598837 -0.0108432  -0.00324737]\n",
      "                 4  [32, 32, 5, 1]               350            0.01         0.95  sigmoid                [-0.01649813 -0.01548823 -0.05148091 -0.01425853 -0.03536548 -0.05001325  -0.0272268  0.00018555\n",
      "                                                                                                           -0.02889633 -0.02839425 -0.01683069 -0.01504196]\n",
      "                 4  [32, 44, 7, 1]               250            0.01         0.95  sigmoid                [-0.00595767 -0.02057654 -0.0635744  -0.0288229  -0.04477933 -0.04786724  -0.0330501  0.000329266\n",
      "                                                                                                           -0.03578765 -0.02078904 -0.00959222 -0.05275403]\n",
      "                 5  [32, 44, 12, 5, 1]           250            0.01         0.95  sigmoid                [-0.01745419 -0.00672211 -0.0485591  -0.0093215  -0.02879113 -0.05074233  -0.0247942  0.000210466\n",
      "                                                                                                           -0.02101006 -0.03277186 -0.01827906 -0.01429104]\n",
      "                 3  [32, 5, 1]                   180            0.005        0.85  relu                   [-0.04393443 -0.04983607 -0.1012459  -0.04918033 -0.08786885 -0.01180328  -0.0578361  0.000693539\n",
      "                                                                                                           -0.08170492 -0.03213115 -0.07540984 -0.0452459 ]\n"
     ]
    }
   ],
   "source": [
    "from PredictorExecutor import PredictorExecutor\n",
    "from NeuralNetPredictor import NeuralNetPredictor\n",
    "from tabulate import tabulate\n",
    "\n",
    "hyperparameters = pd.read_csv(\"./data/neural_network_parameters.csv\")\n",
    "\n",
    "p = PreprocessData()\n",
    "X_in, y_in = p.read_transformed_data_from_file()\n",
    "X_in, y_in = X_in[:10], y_in[:10]\n",
    "\n",
    "predictor_executor = PredictorExecutor()\n",
    "scores_by_hyperparameters = predictor_executor.cross_validation(\n",
    "    hyperparameters,\n",
    "    X_in,\n",
    "    y_in,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    folds=10\n",
    ")\n",
    "\n",
    "print(tabulate(scores_by_hyperparameters, headers='keys', tablefmt='simple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc6d17-6b5b-4ea1-a536-df2a53e13c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
